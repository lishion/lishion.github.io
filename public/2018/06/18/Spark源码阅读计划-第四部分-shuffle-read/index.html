
<!doctype html>
<html class="theme-next use-motion theme-next-mala">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>



  <link href='//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext' rel='stylesheet' type='text/css'>


<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>




  <meta name="keywords" content="Spark,编程," />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description" content="拖了这么久终于把 shuffle read 部分的源码看了一遍了。虽然 shuffle read 再数据合并部分的逻辑要比 shuffle 简单，但是由于这个过程中 executor 要到 master 拉取 shuffle write 结果信息，就涉及到 spark 的 block manager 的一些东西，因此完整的 shuffle read 过程依然是很复杂的。但是由于我还是太菜了，对于">
<meta name="keywords" content="Spark,编程">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark源码阅读计划-第四部分-shuffle read">
<meta property="og:url" content="http://yoursite.com/2018/06/18/Spark源码阅读计划-第四部分-shuffle-read/index.html">
<meta property="og:site_name" content="Lishion&#39;s Blog">
<meta property="og:description" content="拖了这么久终于把 shuffle read 部分的源码看了一遍了。虽然 shuffle read 再数据合并部分的逻辑要比 shuffle 简单，但是由于这个过程中 executor 要到 master 拉取 shuffle write 结果信息，就涉及到 spark 的 block manager 的一些东西，因此完整的 shuffle read 过程依然是很复杂的。但是由于我还是太菜了，对于">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-06-18T14:52:45.546Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark源码阅读计划-第四部分-shuffle read">
<meta name="twitter:description" content="拖了这么久终于把 shuffle read 部分的源码看了一遍了。虽然 shuffle read 再数据合并部分的逻辑要比 shuffle 简单，但是由于这个过程中 executor 要到 master 拉取 shuffle write 结果信息，就涉及到 spark 的 block manager 的一些东西，因此完整的 shuffle read 过程依然是很复杂的。但是由于我还是太菜了，对于">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mala',
    sidebar: 'post'
  };
</script>

  <title> Spark源码阅读计划-第四部分-shuffle read | Lishion's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  



  <div class="container one-column page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">LISHION</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            <i class="menu-item-icon icon-next-categories"></i> <br />
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            Tags
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    
      

      

    

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              Spark源码阅读计划-第四部分-shuffle read
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          Posted on
          <time itemprop="dateCreated" datetime="2018-06-18T10:38:44+08:00" content="2018-06-18">
            2018-06-18
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; In
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/Spark源码阅读计划/" itemprop="url" rel="index">
                  <span itemprop="name">Spark源码阅读计划</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        <span itemprop="articleBody"><p>拖了这么久终于把 shuffle read 部分的源码看了一遍了。虽然 shuffle read 再数据合并部分的逻辑要比 shuffle 简单，但是由于这个过程中 executor 要到 master 拉取 shuffle write 结果信息，就涉及到 spark 的 block manager 的一些东西，因此完整的 shuffle read 过程依然是很复杂的。但是由于我还是太菜了，对于 block manage 这一部分看的一知半解，因此关于 executor 与 master 进行元数据交互的部分也就不会写得很详细，当然还是会涉及到一些。有关 block manage 的这部分以后应该会写到，先立个 flag 在这里吧。</p>
<h2 id="MapStatus"><a href="#MapStatus" class="headerlink" title="MapStatus"></a>MapStatus</h2><p>在 shuffle write 完成之后会返回一个 MapStatus，MapStatus记录了 BlockManagerId 以及最终每个分区的大小。其中 BlockManagerId 包含了 BlockManager 所在的 host 以及 port 等信息。返回的 MapStatus 最终会被 Driver 端获并存储以便于 mapper 端获取。 这里要稍微提一下 BlockManager 的知识，Spark 利用 BlockManager 对数据进行读写，而 Block 就是其中的基本单位。每一个 Block 拥有一个 id。而通过BlockManager 则可以操作这些 Block 。因此 mapper 端只需要知道 BlockManager 的位置以及所需要的文件在哪些 Block 就能获取到对应的数据。这里通过 MapOutputTracker 通过 shuffleid 对一次 shuffle write 中所有的 mapper 产生的 MapStatus 进行了记录。</p>
<p>在每一个 mapper 的 shuffle task 结束后，MapOutputTracker就会将其返回的 MapStatues 进行注册。在 DAGScheduler 中可以看到:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> smt: <span class="type">ShuffleMapTask</span> =&gt;</span><br><span class="line">             <span class="keyword">val</span> shuffleStage = stage.asInstanceOf[<span class="type">ShuffleMapStage</span>]</span><br><span class="line">             <span class="keyword">val</span> status = event.result.asInstanceOf[<span class="type">MapStatus</span>]</span><br><span class="line">             <span class="keyword">val</span> execId = status.location.executorId</span><br><span class="line">		  </span><br><span class="line">             mapOutputTracker.registerMapOutput(</span><br><span class="line">               shuffleStage.shuffleDep.shuffleId, smt.partitionId, status)</span><br></pre></td></tr></table></figure>
<p>这里的 MapOutputTracker 实际的类型为 MapOutputTrackerMaster 。继续看关于注册的代码:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">registerMapOutput</span></span>(shuffleId: <span class="type">Int</span>, mapId: <span class="type">Int</span>, status: <span class="type">MapStatus</span>) &#123;</span><br><span class="line">   shuffleStatuses(shuffleId).addMapOutput(mapId, status)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>shuffleStatuses 实际上是一个 hashmap:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> shuffleStatuses = <span class="keyword">new</span> <span class="type">ConcurrentHashMap</span>[<span class="type">Int</span>, <span class="type">ShuffleStatus</span>]().asScala</span><br></pre></td></tr></table></figure>
<p>ShuffleStatus 是一个类，里面包含了一个 MapStatus 数组。也就是说，通过在 shuffle write 之前注册的 shuffle 所用的 shuffleid 作为索引存储了 shuffle write 过程产生的 MapStatus。而 MapOutputTrackerMaster 是用于 Driver 端的。用于 Executor 的则是 MapOutputTrackerWorker 。在 MapOutputTrackerWorker 中一开始是没有 shuffleStatuses 的。需要从 MapOutputTrackerMaster 中获取。</p>
<h2 id="shuffle-read"><a href="#shuffle-read" class="headerlink" title="shuffle read"></a>shuffle read</h2><p>shuffle read 代码开始于 Shuffled 中的 compute 方法:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)] = &#123;</span><br><span class="line">    <span class="keyword">val</span> dep = dependencies.head.asInstanceOf[<span class="type">ShuffleDependency</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>]]</span><br><span class="line">    <span class="type">SparkEnv</span>.get.shuffleManager.getReader(dep.shuffleHandle, split.index, split.index + <span class="number">1</span>, context)</span><br><span class="line">      .read()</span><br><span class="line">      .asInstanceOf[<span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)]]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>可以看到这里传入了需要计算的分区。代码中获取了一个 reader 并调用了其 read 方法。 getReader 代码如下:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getReader</span></span>[<span class="type">K</span>, <span class="type">C</span>](</span><br><span class="line">    handle: <span class="type">ShuffleHandle</span>,</span><br><span class="line">    startPartition: <span class="type">Int</span>,</span><br><span class="line">    endPartition: <span class="type">Int</span>,</span><br><span class="line">    context: <span class="type">TaskContext</span>): <span class="type">ShuffleReader</span>[<span class="type">K</span>, <span class="type">C</span>] = &#123;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">BlockStoreShuffleReader</span>(</span><br><span class="line">    handle.asInstanceOf[<span class="type">BaseShuffleHandle</span>[<span class="type">K</span>, _, <span class="type">C</span>]], startPartition, endPartition, context)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际上是返回了一个 BlockStoreShuffleReader 。read 方法较长，准备一段一段的讲解:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(): <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]]</span><br></pre></td></tr></table></figure>
<p>方法返回了一个 Iterator。方法的开始定义了一个:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> wrappedStreams = <span class="keyword">new</span> <span class="type">ShuffleBlockFetcherIterator</span>(</span><br><span class="line">     context,</span><br><span class="line">     blockManager.shuffleClient,</span><br><span class="line">     blockManager,</span><br><span class="line">     <span class="comment">// 获取 blockManagerId 与　blockId</span></span><br><span class="line">     mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition),</span><br><span class="line">     serializerManager.wrapStream,</span><br><span class="line">     <span class="comment">// Note: we use getSizeAsMb when no suffix is provided for backwards compatibility</span></span><br><span class="line">     <span class="type">SparkEnv</span>.get.conf.getSizeAsMb(<span class="string">"spark.reducer.maxSizeInFlight"</span>, <span class="string">"48m"</span>) * <span class="number">1024</span> * <span class="number">1024</span>,</span><br><span class="line">     <span class="type">SparkEnv</span>.get.conf.getInt(<span class="string">"spark.reducer.maxReqsInFlight"</span>, <span class="type">Int</span>.<span class="type">MaxValue</span>),</span><br><span class="line">     <span class="type">SparkEnv</span>.get.conf.get(config.<span class="type">REDUCER_MAX_BLOCKS_IN_FLIGHT_PER_ADDRESS</span>),</span><br><span class="line">     <span class="type">SparkEnv</span>.get.conf.get(config.<span class="type">MAX_REMOTE_BLOCK_SIZE_FETCH_TO_MEM</span>),</span><br><span class="line">     <span class="type">SparkEnv</span>.get.conf.getBoolean(<span class="string">"spark.shuffle.detectCorrupt"</span>, <span class="literal">true</span>))</span><br></pre></td></tr></table></figure>
<p>这个 wrappedStreams 实际上获取数据的输入流。看看:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getMapSizesByExecutorId</span></span>(shuffleId: <span class="type">Int</span>, startPartition: <span class="type">Int</span>, endPartition: <span class="type">Int</span>)</span><br><span class="line">     : <span class="type">Iterator</span>[(<span class="type">BlockManagerId</span>, <span class="type">Seq</span>[(<span class="type">BlockId</span>, <span class="type">Long</span>)])] = &#123;</span><br><span class="line">   logDebug(<span class="string">s"Fetching outputs for shuffle <span class="subst">$shuffleId</span>, partitions <span class="subst">$startPartition</span>-<span class="subst">$endPartition</span>"</span>)</span><br><span class="line">   <span class="comment">// 通过本次的 shuffleId 先获取 mapper 端产生的 MapStatuses</span></span><br><span class="line">   <span class="keyword">val</span> statuses = getStatuses(shuffleId)</span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// </span></span><br><span class="line">     <span class="type">MapOutputTracker</span>.convertMapStatuses(shuffleId, startPartition, endPartition, statuses)</span><br><span class="line">   &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> e: <span class="type">MetadataFetchFailedException</span> =&gt;</span><br><span class="line">       <span class="comment">// We experienced a fetch failure so our mapStatuses cache is outdated; clear it:</span></span><br><span class="line">       mapStatuses.clear()</span><br><span class="line">       <span class="keyword">throw</span> e</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>随后调用了 convertMapStatuses:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convertMapStatuses</span></span>(</span><br><span class="line">      shuffleId: <span class="type">Int</span>,</span><br><span class="line">      startPartition: <span class="type">Int</span>,</span><br><span class="line">      endPartition: <span class="type">Int</span>,</span><br><span class="line">      statuses: <span class="type">Array</span>[<span class="type">MapStatus</span>]): <span class="type">Iterator</span>[(<span class="type">BlockManagerId</span>, <span class="type">Seq</span>[(<span class="type">BlockId</span>, <span class="type">Long</span>)])] = &#123;</span><br><span class="line">    assert (statuses != <span class="literal">null</span>)</span><br><span class="line">    <span class="keyword">val</span> splitsByAddress = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">BlockManagerId</span>, <span class="type">ListBuffer</span>[(<span class="type">BlockId</span>, <span class="type">Long</span>)]]</span><br><span class="line">    <span class="keyword">for</span> ((status, mapId) &lt;- statuses.iterator.zipWithIndex) &#123;</span><br><span class="line">      <span class="keyword">if</span> (status == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">val</span> errorMessage = <span class="string">s"Missing an output location for shuffle <span class="subst">$shuffleId</span>"</span></span><br><span class="line">        logError(errorMessage)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">MetadataFetchFailedException</span>(shuffleId, startPartition, errorMessage)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (part &lt;- startPartition until endPartition) &#123;</span><br><span class="line">          <span class="keyword">val</span> size = status.getSizeForBlock(part) <span class="comment">// 这里只获取了需要处理的分区对应的数据</span></span><br><span class="line">          <span class="keyword">if</span> (size != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 这里获取到需要计算的分区数据所在的 block。其实就是由 shuffleId, mapId, part</span></span><br><span class="line">            <span class="comment">// 这三个组成的</span></span><br><span class="line">            splitsByAddress.getOrElseUpdate(status.location, <span class="type">ListBuffer</span>()) +=</span><br><span class="line">                ((<span class="type">ShuffleBlockId</span>(shuffleId, mapId, part), size))</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    splitsByAddress.iterator</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>这里涉及到 mapId 和 part 这两个变量。实际上，这两个都是分区的 Id 。只不过 mapId 是 mapper 端对应的分区Id，而 part 是经过 shuffle 之后 reducer 端对应的分区Id。通过<code>convertMapStatuses</code>就可以得到需要从哪些 Block 拉取数据。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取　block　对应的输入流</span></span><br><span class="line"><span class="keyword">val</span> recordIter = wrappedStreams.flatMap &#123; <span class="keyword">case</span> (blockId, wrappedStream) =&gt;</span><br><span class="line">      <span class="comment">// Note: the asKeyValueIterator below wraps a key/value iterator inside of a</span></span><br><span class="line">      <span class="comment">// NextIterator. The NextIterator makes sure that close() is called on the</span></span><br><span class="line">      <span class="comment">// underlying InputStream when all records have been read.</span></span><br><span class="line">      serializerInstance.deserializeStream(wrappedStream).asKeyValueIterator</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Update the context task metrics for each record read.</span></span><br><span class="line">    <span class="keyword">val</span> readMetrics = context.taskMetrics.createTempShuffleReadMetrics()</span><br><span class="line">    <span class="keyword">val</span> metricIter = <span class="type">CompletionIterator</span>[(<span class="type">Any</span>, <span class="type">Any</span>), <span class="type">Iterator</span>[(<span class="type">Any</span>, <span class="type">Any</span>)]](</span><br><span class="line">      recordIter.map &#123; record =&gt;</span><br><span class="line">        readMetrics.incRecordsRead(<span class="number">1</span>)</span><br><span class="line">        record</span><br><span class="line">      &#125;,</span><br><span class="line">      context.taskMetrics().mergeShuffleReadMetrics())</span><br><span class="line"></span><br><span class="line">    <span class="comment">// An interruptible iterator must be used here in order to support task cancellation</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">val</span> interruptibleIter = <span class="keyword">new</span> <span class="type">InterruptibleIterator</span>[(<span class="type">Any</span>, <span class="type">Any</span>)](context, metricIter)</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">val</span> aggregatedIter: <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] = <span class="keyword">if</span> (dep.aggregator.isDefined) &#123;</span><br><span class="line">      　<span class="comment">// 如果需要聚合</span></span><br><span class="line">        <span class="keyword">if</span> (dep.mapSideCombine) &#123;</span><br><span class="line">        <span class="comment">// We are reading values that are already combined</span></span><br><span class="line">        <span class="keyword">val</span> combinedKeyValuesIterator = interruptibleIter.asInstanceOf[<span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)]]</span><br><span class="line">        dep.aggregator.get.combineCombinersByKey(combinedKeyValuesIterator, context)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// We don't know the value type, but also don't care -- the dependency *should*</span></span><br><span class="line">        <span class="comment">// have made sure its compatible w/ this aggregator, which will convert the value</span></span><br><span class="line">        <span class="comment">// type to the combined type C</span></span><br><span class="line">        <span class="keyword">val</span> keyValuesIterator = interruptibleIter.asInstanceOf[<span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">Nothing</span>)]]</span><br><span class="line">        dep.aggregator.get.combineValuesByKey(keyValuesIterator, context)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      interruptibleIter.asInstanceOf[<span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]]]</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这里进行聚合的代码实际上在 combineCombinersByKey 中:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineCombinersByKey</span></span>(</span><br><span class="line">    iter: <span class="type">Iterator</span>[_ &lt;: <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]],</span><br><span class="line">    context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)] = &#123;</span><br><span class="line">  <span class="keyword">val</span> combiners = <span class="keyword">new</span> <span class="type">ExternalAppendOnlyMap</span>[<span class="type">K</span>, <span class="type">C</span>, <span class="type">C</span>](identity, mergeCombiners, mergeCombiners)</span><br><span class="line">  <span class="comment">// 这里的 insertAll 和　shuffle write 中的 insertAll 效果一样，会排序生成临时文件</span></span><br><span class="line">  combiners.insertAll(iter)</span><br><span class="line">  updateMetrics(context, combiners)</span><br><span class="line">  combiners.iterator</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终返回了 iterator:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">iterator</span></span>: <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)] = &#123;</span><br><span class="line">   <span class="keyword">if</span> (currentMap == <span class="literal">null</span>) &#123;</span><br><span class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(</span><br><span class="line">       <span class="string">"ExternalAppendOnlyMap.iterator is destructive and should only be called once."</span>)</span><br><span class="line">   &#125;</span><br><span class="line">    <span class="comment">//　如果没有生成临时文件</span></span><br><span class="line">   <span class="keyword">if</span> (spilledMaps.isEmpty) &#123;</span><br><span class="line">     <span class="type">CompletionIterator</span>[(<span class="type">K</span>, <span class="type">C</span>), <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)]](</span><br><span class="line">       destructiveIterator(currentMap.iterator), freeCurrentMap())</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     <span class="keyword">new</span> <span class="type">ExternalIterator</span>()</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>如果有零时文件生成会返回一个 ExternalIterator :</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> mergeHeap = <span class="keyword">new</span> mutable.<span class="type">PriorityQueue</span>[<span class="type">StreamBuffer</span>]</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> sortedMap = <span class="type">CompletionIterator</span>[(<span class="type">K</span>, <span class="type">C</span>), <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)]](destructiveIterator(</span><br><span class="line">      currentMap.destructiveSortedIterator(keyComparator)), freeCurrentMap())</span><br><span class="line">    <span class="comment">// 这里合并了临时文件与内存中的数据</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">val</span> inputStreams = (<span class="type">Seq</span>(sortedMap) ++ spilledMaps).map(it =&gt; it.buffered)</span><br><span class="line">    inputStreams.foreach &#123; it =&gt;</span><br><span class="line">      <span class="keyword">val</span> kcPairs = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[(<span class="type">K</span>, <span class="type">C</span>)]</span><br><span class="line">      readNextHashCode(it, kcPairs)</span><br><span class="line">      <span class="keyword">if</span> (kcPairs.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        mergeHeap.enqueue(<span class="keyword">new</span> <span class="type">StreamBuffer</span>(it, kcPairs))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这里涉及到了一个很重要的类 ArrayBuffer:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">StreamBuffer</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    val iterator: <span class="type">BufferedIterator</span>[(<span class="type">K</span>, <span class="type">C</span></span>)],</span></span><br><span class="line"><span class="class">    <span class="title">val</span> <span class="title">pairs</span></span>: <span class="type">ArrayBuffer</span>[(<span class="type">K</span>, <span class="type">C</span>)])</span><br><span class="line">  <span class="keyword">extends</span> <span class="type">Comparable</span>[<span class="type">StreamBuffer</span>] &#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isEmpty</span></span>: <span class="type">Boolean</span> = pairs.length == <span class="number">0</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">minKeyHash</span></span>: <span class="type">Int</span> = &#123;</span><br><span class="line">    assert(pairs.length &gt; <span class="number">0</span>)</span><br><span class="line">    hashKey(pairs.head)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compareTo</span></span>(other: <span class="type">StreamBuffer</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (other.minKeyHash &lt; minKeyHash) <span class="number">-1</span> <span class="keyword">else</span> <span class="keyword">if</span> (other.minKeyHash == minKeyHash) <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>StreamBuffer 实际上维持了一个 iterator 与一个数组。并且重写了 compareTo 方法。是通过数据中第一个元素的 key 也就是minKeyHash来比较大小。而代码:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">readNextHashCode(it, kcPairs)</span><br><span class="line">     <span class="keyword">if</span> (kcPairs.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">       mergeHeap.enqueue(<span class="keyword">new</span> <span class="type">StreamBuffer</span>(it, kcPairs))</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>
<p>再看 next 方法:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): (<span class="type">K</span>, <span class="type">C</span>) = &#123;</span><br><span class="line">  <span class="keyword">if</span> (mergeHeap.isEmpty) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoSuchElementException</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Select a key from the StreamBuffer that holds the lowest key hash</span></span><br><span class="line">  <span class="comment">//　这里需要注意的是每一个 StreamBuffer 中的数组的元素是按照 key 经过排序的，mergeHeap 中的 StreamBuffer 也是按照 minKeyHash 进行排序的。也就是从 mergeHeap 每取出一个StreamBuffer，其对应的数组中 key 的 hash 一定是目前 mergeHeap 中所有数组中 key 最小的，如果能理解这一点，那这里的 merge 就基本可以理解了。</span></span><br><span class="line">  <span class="keyword">val</span> minBuffer = mergeHeap.dequeue()</span><br><span class="line">  <span class="keyword">val</span> minPairs = minBuffer.pairs</span><br><span class="line">  <span class="keyword">val</span> minHash = minBuffer.minKeyHash</span><br><span class="line">  <span class="keyword">val</span> minPair = removeFromBuffer(minPairs, <span class="number">0</span>)</span><br><span class="line">  <span class="keyword">val</span> minKey = minPair._1</span><br><span class="line">  <span class="keyword">var</span> minCombiner = minPair._2</span><br><span class="line">  assert(hashKey(minPair) == minHash)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For all other streams that may have this key (i.e. have the same minimum key hash),</span></span><br><span class="line">  <span class="comment">// merge in the corresponding value (if any) from that stream</span></span><br><span class="line">  <span class="keyword">val</span> mergedBuffers = <span class="type">ArrayBuffer</span>[<span class="type">StreamBuffer</span>](minBuffer)</span><br><span class="line">  <span class="comment">// 如果下一个 StreamBuffer 中的 minKeyHash 相同，则可能会含有相同的 key，则需要合并。这里由于是经过排序的，所以不用遍历所有的 StreamBuffer。只要下一个不同，则后面一定不会有与当前 minKeyHash 相同的的 StreamBuffer。</span></span><br><span class="line">  <span class="keyword">while</span> (mergeHeap.nonEmpty &amp;&amp; mergeHeap.head.minKeyHash == minHash) &#123;</span><br><span class="line">    <span class="keyword">val</span> newBuffer = mergeHeap.dequeue()</span><br><span class="line">    <span class="comment">// 这里如果有相同的 key 则进行合并</span></span><br><span class="line">    <span class="comment">// 注意，hash 相同 key 不一定相同</span></span><br><span class="line">    minCombiner = mergeIfKeyExists(minKey, minCombiner, newBuffer)</span><br><span class="line">    mergedBuffers += newBuffer</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Repopulate each visited stream buffer and add it back to the queue if it is non-empty</span></span><br><span class="line">  </span><br><span class="line">  mergedBuffers.foreach &#123; buffer =&gt;</span><br><span class="line">    <span class="comment">// 如果 key 被合并完了，就需要读取下一批hash相同的key的数据到ArrayBuffer的数组中</span></span><br><span class="line">    <span class="keyword">if</span> (buffer.isEmpty) &#123;</span><br><span class="line">      readNextHashCode(buffer.iterator, buffer.pairs)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!buffer.isEmpty) &#123;</span><br><span class="line">      <span class="comment">// 刚才dequeue的 ArrayBuffer的数组中可能有没合并完的数据 </span></span><br><span class="line">      <span class="comment">// 或者有新读取的数据则需要继续放入 mergeHeap 中进行合并 </span></span><br><span class="line">      mergeHeap.enqueue(buffer)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 返回合并完的数据</span></span><br><span class="line">  <span class="comment">// 注意这里的 key 只是按照 hash 进行排序的，在 ExternalSorter 才是按照用户定义的排序方式进行排序</span></span><br><span class="line">  (minKey, minCombiner)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果不需要排序，shuffle read 就算完成了。但是如果需要排序则:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> resultIter = dep.keyOrdering <span class="keyword">match</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> <span class="type">Some</span>(keyOrd: <span class="type">Ordering</span>[<span class="type">K</span>]) =&gt;</span><br><span class="line">       <span class="comment">// Create an ExternalSorter to sort the data.</span></span><br><span class="line">       <span class="keyword">val</span> sorter =</span><br><span class="line">         <span class="keyword">new</span> <span class="type">ExternalSorter</span>[<span class="type">K</span>, <span class="type">C</span>, <span class="type">C</span>](context, ordering = <span class="type">Some</span>(keyOrd), serializer = dep.serializer)</span><br><span class="line">       sorter.insertAll(aggregatedIter)</span><br><span class="line">       context.taskMetrics().incMemoryBytesSpilled(sorter.memoryBytesSpilled)</span><br><span class="line">       context.taskMetrics().incDiskBytesSpilled(sorter.diskBytesSpilled)</span><br><span class="line">       context.taskMetrics().incPeakExecutionMemory(sorter.peakMemoryUsedBytes)</span><br><span class="line">       <span class="comment">// Use completion callback to stop sorter if task was finished/cancelled.</span></span><br><span class="line">       context.addTaskCompletionListener(_ =&gt; &#123;</span><br><span class="line">         sorter.stop()</span><br><span class="line">       &#125;)</span><br><span class="line">       <span class="type">CompletionIterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>], <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]]](sorter.iterator, sorter.stop())</span><br><span class="line">     <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">       aggregatedIter</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   resultIter <span class="keyword">match</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> _: <span class="type">InterruptibleIterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] =&gt; resultIter</span><br><span class="line">     <span class="keyword">case</span> _ =&gt;</span><br><span class="line">       <span class="comment">// Use another interruptible iterator here to support task cancellation as aggregator</span></span><br><span class="line">       <span class="comment">// or(and) sorter may have consumed previous interruptible iterator.</span></span><br><span class="line">       <span class="keyword">new</span> <span class="type">InterruptibleIterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]](context, resultIter)</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>这里依然使用了 ExternalSorter 进行排序，而最终使用了 ExternalSorter 的 iterator 方法。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iterator</span></span>: <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] = &#123;</span><br><span class="line">  isShuffleSort = <span class="literal">false</span></span><br><span class="line">  partitionedIterator.flatMap(pair =&gt; pair._2)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中 partitionedIterator 方法在 shuffle write 部分已经讲的很清楚了。有兴趣的可以去看看。这里 shuffle read 就基本结束了。其中从其他 Executor 拉取数据的部分由于涉及很多，这里就基本没有怎么讲解。以后可能会专门开一篇文章。</p>
</span>
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Spark/" rel="tag">#Spark</a>
          
            <a href="/tags/编程/" rel="tag">#编程</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/20/使用travis自动部署hexo到github/" rel="prev">使用travis自动部署hexo到github</a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/15/Spark优化-减少分区/" rel="next">Spark调优-选择合适的分区</a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div>
      
    </div>

    <div class="post-spread">
      
        <div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
	<a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a>
	<a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
</div>
<script>
    window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>

 </div>

        

        
          <div class="comments" id="comments">
            
          </div>
        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table Of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/default_avatar.jpg" alt="lishion" itemprop="image"/>
          <p class="site-author-name" itemprop="name">lishion</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">8</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">4</span>
              <span class="site-state-item-name">categories</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">5</span>
              <span class="site-state-item-name">tags</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/lishion" target="_blank">GitHub</a>
              </span>
            
          
        </div>

        <div class="links-of-friendly motion-element">
          
        </div>

        
        

      </section>

      
        <section class="post-toc-wrap sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#MapStatus"><span class="nav-number">1.</span> <span class="nav-text">MapStatus</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#shuffle-read"><span class="nav-number">2.</span> <span class="nav-text">shuffle read</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </section>
      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp; 
  <span itemprop="copyrightYear">2018
  </span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lishion
  </span>
</div>

<!-- <div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div> -->

<!-- <div class="theme-info">
  Theme by <a class="theme-link" href="http://blog.guxiangfly.cn">guxiangfly</a>.<a class="theme-link" href="https://github.com/GuXiangFly/next-guxiangfly">next-guxiangfly</a>
</div> -->

<!-- busuanzi -->



 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    
    

  


  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.5.1" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 0.4 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    var $tocContent = $('.post-toc-content');
    if (isDesktop() && CONFIG.sidebar === 'post') {
      if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
        displaySidebar();
      }
    }
  });
</script>



  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
</body>
</html>
